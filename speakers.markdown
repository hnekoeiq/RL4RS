---
layout: page
title: Speakers
permalink: /speakers/
---

<ol>
  <li>
    <table style="border: none;">
      <tr>
        <td><img src="https://anikem.github.io/images/profile_aniK.jpg" alt="Speaker 1" style="width:600px;"/></td>
        <td><p><b>Aniruddha Kembhavi:</b>  is an Affiliate Associate Professor at the Computer Science & Engineering Department at the University of Washington. He also leads PRIOR, the computer vision team at the Allen Institute for AI. His research interest is at the intersection of vision, language, and embodiment. He has pioneered several futuristic multimodal foundational works such as Unified-IO.</p></td>
      </tr>
    </table>
  </li>
  <li>
    <table style="border: none;">
      <tr>
        <td><img src="https://aisecure.github.io/files/bo_li_headshot.jpg" alt="Speaker 2" style="width:600px;"/></td>
        <td><p><b>Bo Li</b>: is an Associate Professor in the Computer Science Department at the University of Chicago. She is also on the advisory board of the Center for Artificial Intelligence Innovation (CAII). Her research focuses on trustworthy machine learning, emphasizing robustness, privacy, generalization, and their interconnections.</p></td>
      </tr>
    </table>
  </li>
  <li>
    <table style="border: none;">
      <tr>
        <td><img src="https://www.cs.umd.edu/sites/default/files/styles/medium/public/images/userpictures/Soheil%20Feizi-profile%20pic.jpg?itok=TzEmxITm" alt="Speaker 3" style="width:600px;"/></td>
        <td><p><b>Soheil Feizi</b>: is an Associate Professor in the Computer Science Department at the University of Maryland. His research is centered around developing reliable and trustworthy Artificial Intelligence (AI) with a focus on understanding its robustness (to natural and/or adversarial noise), generalizability (to unforeseen data domains), and interpretability (of both test and training time predictions). </p></td>
      </tr>
    </table>
  </li>
  <li>
    <table style="border: none;">
      <tr>
        <td><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CYI6cKgAAAAJ&citpid=2" alt="Speaker 4" style="width:600px;"/></td>
        <td><p><b>David Bau</b>: is an Assistant Professor of Computer Science at Northeastern Khoury College. His interests lie in studying the structure and interpretation of deep networks, specifically large generative models. More specifically, his recent works include interpreting these large models and how to erase or rewrite the concepts.</p></td>
      </tr>
    </table>
  </li>
  <li>
    <table style="border: none;">
      <tr>
        <td><img src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=eXKdSu0AAAAJ&citpid=6" alt="Speaker 5" style="width:600px;"/></td>
        <td><p><b>Yanjun Qi</b>: is a Senior Manager at Bedrock Science, Amazon Web Services (AWS). She is also an associate professor of the University of Virginia, Department of Computer Science since 2013. Dr. Qi's research focuses on trustworthy deep learning, particularly trustworthy natural language processing (NLP), exploring ways to make deep learning models more reliable and interpretable. By combining her industry experience at AWS and academic expertise, Dr. Qi contributes to the development of trustworthy and robust AI systems.</p></td>
      </tr>
    </table>
  </li>
</ol>